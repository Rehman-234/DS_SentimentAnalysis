# -*- coding: utf-8 -*-
"""Crypto.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ug3fiNwFuLdPBYjz4daI4UJnvQWCD1G4
"""

!pip install nltk
!pip install vaderSentiment
!pip install scikit-learn
!pip install pandas
!pip install yfinance

import pandas as pd
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# Download necessary NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt_tab') # Download the punkt_tab model for tokenization


stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    if isinstance(text, str):
        text = re.sub(r'[^a-zA-Z\s]', '', text)  # Remove special chars
        text = text.lower()
        tokens = nltk.word_tokenize(text)
        tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]
        return ' '.join(tokens)
    return ""

# Load your dataset
df = pd.read_csv('/content/dataset_52-person-from-2021-02-05_2023-06-12_21-34-17-266_with_sentiment.csv', encoding='ISO-8859-1')
df = df.dropna(subset=['full_text'])
df['clean_text'] = df['full_text'].apply(preprocess_text)

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

analyzer = SentimentIntensityAnalyzer()

def vader_sentiment(text):
    score = analyzer.polarity_scores(text)['compound']
    if score >= 0.05:
        return 'positive'
    elif score <= -0.05:
        return 'negative'
    else:
        return 'neutral'

df['sentiment'] = df['clean_text'].apply(vader_sentiment)

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report

# You need a labeled dataset for training this
# For example purposes, letâ€™s assume df already has a 'label' column
X = df['clean_text']
y = df['sentiment']  # This must be labeled: 'positive', 'negative', 'neutral'

tfidf = TfidfVectorizer(max_features=3000)
X_tfidf = tfidf.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)

nb_model = MultinomialNB()
nb_model.fit(X_train, y_train)

preds = nb_model.predict(X_test)
print(classification_report(y_test, preds))

!pip install transformers

from transformers import pipeline

# Load lightweight sentiment pipeline
classifier = pipeline("sentiment-analysis", model="distilbert-base-uncased-finetuned-sst-2-english")

def distilbert_sentiment(text):
    try:
        result = classifier(text[:512])[0]  # Truncate to 512 tokens
        return result['label'].lower()
    except:
        return 'neutral'

df['sentiment'] = df['clean_text'].apply(distilbert_sentiment)

import yfinance as yf
import pandas as pd

# Download Bitcoin data
btc = yf.download('BTC-USD', start='2022-01-01', end='2023-12-31')
# Force btc to have a single-level index with 'Date' as a column
btc = btc.reset_index()
print("btc DataFrame structure after download and reset_index:")
print(btc.head())  # Print the first few rows of btc
print(btc.columns) # Print the columns of btc

# Assuming 'created_at' is your date column in df
df['date'] = pd.to_datetime(df['created_at']).dt.date
btc['Date'] = pd.to_datetime(btc['Date']).dt.date

# Convert 'date' columns to strings
df['date'] = df['date'].astype(str)
btc['Date'] = btc['Date'].astype(str)

print("\ndf['date'] column details:")
print(df['date'].head())  # Print the first few values of df['date']
print(df['date'].dtype)  # Print the data type of df['date']

print("\nbtc['Date'] column details:")
print(btc['Date'].head())  # Print the first few values of btc['Date']
print(btc['Date'].dtype)  # Print the data type of btc['Date']

# Calculate daily sentiment
daily_sentiment = df.groupby('date')['sentiment'].value_counts(normalize=True).unstack().fillna(0)
daily_sentiment = daily_sentiment.reset_index()

print("\ndaily_sentiment DataFrame structure:")
print(daily_sentiment.head())  # Print the first few rows of daily_sentiment
print(daily_sentiment.columns) # Print the columns of daily_sentiment

btc = btc.droplevel(level=0, axis=1) if isinstance(btc.columns, pd.MultiIndex) else btc  # Drop extra level if exists
daily_sentiment.columns = daily_sentiment.columns.get_level_values(0) if isinstance(daily_sentiment.columns, pd.MultiIndex) else daily_sentiment.columns # Drop extra level if exists

import yfinance as yf
import pandas as pd

# Download Bitcoin data
btc = yf.download('BTC-USD', start='2022-01-01', end='2023-12-31')
# Force btc to have a single-level index with 'Date' as a column
btc = btc.reset_index()


df['date'] = pd.to_datetime(df['created_at']).dt.date
btc['Date'] = pd.to_datetime(btc['Date']).dt.date

# Convert 'date' columns to strings for merging
df['date'] = df['date'].astype(str)
btc['Date'] = btc['Date'].astype(str)

# Calculate daily sentiment
daily_sentiment = df.groupby('date')['sentiment'].value_counts(normalize=True).unstack().fillna(0)
daily_sentiment = daily_sentiment.reset_index()

# Ensure both 'Date' columns are at the same level and type
btc.columns = btc.columns.get_level_values(0) if isinstance(btc.columns, pd.MultiIndex) else btc.columns
daily_sentiment.columns = daily_sentiment.columns.get_level_values(0) if isinstance(daily_sentiment.columns, pd.MultiIndex) else daily_sentiment.columns

# Merge DataFrames using 'inner' join on 'Date' column
merged = pd.merge(btc, daily_sentiment, left_on='Date', right_on='date', how='inner')

# Drop the redundant 'date' column after merging
merged = merged.drop(columns=['date'])

# Print some info for debugging
print("btc columns:", btc.columns)
print("daily_sentiment columns:", daily_sentiment.columns)
print("merged columns:", merged.columns)



# Calculate and print correlation

# Ensure merged DataFrame has the expected columns
if 'Close' in merged.columns and 'positive' in merged.columns and 'negative' in merged.columns:
    correlation = merged[['Close', 'positive', 'negative']].corr()  # Include only available columns
    print("\nCorrelation Matrix:")
    print(correlation)
else:
    print("Error: Expected columns not found in merged DataFrame.")
# ---END MODIFIED SECTION--- #

import seaborn as sns
import matplotlib.pyplot as plt

# Heatmap for correlation matrix
plt.figure(figsize=(8, 6))
sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation between Bitcoin Price and Sentiment')
plt.show()

# Line plots for Bitcoin price and sentiment scores over time
merged['Date'] = pd.to_datetime(merged['Date']) # Convert 'Date' column to datetime
merged.set_index('Date', inplace=True) # Set 'Date' as index

fig, ax1 = plt.subplots(figsize=(12, 6))

# Plot Bitcoin closing price
color = 'tab:blue'
ax1.set_xlabel('Date')
ax1.set_ylabel('Bitcoin Close Price', color=color)
ax1.plot(merged['Close'], color=color)
ax1.tick_params(axis='y', labelcolor=color)

# Create a second y-axis for sentiment scores
ax2 = ax1.twinx()

# Plot positive sentiment score
color = 'tab:green'
ax2.set_ylabel('Positive Sentiment', color=color)
ax2.plot(merged['positive'], color=color, linestyle='--')
ax2.tick_params(axis='y', labelcolor=color)

# Plot negative sentiment score
color = 'tab:red'
ax2.plot(merged['negative'], color=color, linestyle='--')

# Add title and legend
plt.title('Bitcoin Price and Sentiment Over Time')
fig.tight_layout()
plt.show()

from sklearn.linear_model import LogisticRegression

#  `X_tfidf` and `y` are already defined (from earlier step)
logreg = LogisticRegression(max_iter=1000)
logreg.fit(X_train, y_train)

log_preds = logreg.predict(X_test)
print("Logistic Regression Results:\n", classification_report(y_test, log_preds))