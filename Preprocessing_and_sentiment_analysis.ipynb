{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d962405",
      "metadata": {
        "id": "5d962405"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install xformers\n",
        "!pip install yahooquery\n",
        "!pip install yfinance\n",
        "!pip install yahoofinancials\n",
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74aae4ab",
      "metadata": {
        "id": "74aae4ab"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from numpy import NaN\n",
        "import spacy\n",
        "from transformers import pipeline\n",
        "import re\n",
        "import nltk\n",
        "from textblob import TextBlob\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, LSTM, Attention, Dropout, GlobalAveragePooling1D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import tensorflow as tf\n",
        "from transformers import TFRobertaModel\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.sentiment.util import *\n",
        "from textblob import TextBlob\n",
        "\n",
        "from yahoofinancials import YahooFinancials\n",
        "from google.colab import drive\n",
        "\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c8d80fe",
      "metadata": {
        "id": "9c8d80fe"
      },
      "source": [
        "## **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ea7906e",
      "metadata": {
        "id": "4ea7906e"
      },
      "outputs": [],
      "source": [
        "# Preprocessing function\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):\n",
        "        # remove punctuation and special characters\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        # convert to lowercase\n",
        "        text = text.lower()\n",
        "        # tokenize text\n",
        "        tokens = nltk.word_tokenize(text)\n",
        "        # remove stop words\n",
        "        tokens = [token for token in tokens if token not in stop_words]\n",
        "        # lemmatize text\n",
        "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "        # join tokens back into text\n",
        "        text = ' '.join(tokens)\n",
        "    return text\n",
        "\n",
        "file_path = 'dataset_50-person-from-2021-02-05_2023-06-12_21-34-17-266.csv'\n",
        "# Load the Excel file into a DataFrame\n",
        "df = pd.read_csv(file_path,encoding='ISO-8859-1')\n",
        "\n",
        "# Remove rows with \"na\" values\n",
        "df = df.dropna(subset=['full_text'])\n",
        "\n",
        "# Fill missing values in 'full_text' column with an empty string\n",
        "df['full_text'] = df['full_text'].fillna('')\n",
        "# to lower text\n",
        "df['full_text'] = df['full_text'].str.lower()\n",
        "# Preprocess the 'full_text' column\n",
        "df['clean_text'] = df['full_text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b168810",
      "metadata": {
        "id": "4b168810"
      },
      "outputs": [],
      "source": [
        "# Filter the DataFrame to keep rows where \"created_at\" is greater than or equal to 2021-01-01\n",
        "df = df[df['created_at'] >= '2021-01-01']\n",
        "import datetime\n",
        "# Convert the \"created_at\" column to datetime format\n",
        "df['created_at'] = pd.to_datetime(df['created_at'])\n",
        "\n",
        "# Extract the date part from the datetime and convert it to the desired format\n",
        "df['created_at'] = df['created_at'].dt.strftime(\"%Y-%m-%d\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c49afa8",
      "metadata": {
        "id": "6c49afa8"
      },
      "source": [
        "#### **add importance_coefficient per tweets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a57969cc",
      "metadata": {
        "id": "a57969cc"
      },
      "outputs": [],
      "source": [
        "df['importance_coefficient'] = df['retweet_count'] + 2 * df['favorite_count'] + 0.5 * df['reply_count']\n",
        "# Find the minimum and maximum values of the importance coefficient\n",
        "min_value = df['importance_coefficient'].min()\n",
        "max_value = df['importance_coefficient'].max()\n",
        "\n",
        "# Normalize the importance coefficient\n",
        "df['importance_coefficient_normalized'] = (df['importance_coefficient'] - min_value) / (max_value - min_value)\n",
        "# Sort the DataFrame based on the \"created_at\" column in ascending order\n",
        "df = df.sort_values('created_at', ascending=True)\n",
        "\n",
        "# Print the sorted DataFrame\n",
        "df.head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}